<!doctype html><html lang=en><head><title>Kaleidoscope Performance with MCJIT - The LLVM Project Blog</title>
<meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="LLVM Project News and Details from the Trenches"><meta name=author content="Andy Kaylor"><meta property="og:url" content="https://blog.llvm.org/2013/07/kaleidoscope-performance-with-mcjit.html"><meta property="og:site_name" content="The LLVM Project Blog"><meta property="og:title" content="Kaleidoscope Performance with MCJIT"><meta property="og:description" content="In a previous post I described the process of porting the LLVM Kaleidoscope tutorial program to use MCJIT as its execution engine.  After navigating through a serious of road blocks we ended up with an implementation that was working as expected."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2013-07-29T12:11:00+00:00"><meta property="article:modified_time" content="2013-07-29T12:11:00+00:00"><meta property="article:tag" content="MC"><meta property="article:tag" content="Jit"><meta name=twitter:card content="summary"><meta name=twitter:title content="Kaleidoscope Performance with MCJIT"><meta name=twitter:description content="In a previous post I described the process of porting the LLVM Kaleidoscope tutorial program to use MCJIT as its execution engine.  After navigating through a serious of road blocks we ended up with an implementation that was working as expected."><meta name=generator content="Hugo 0.128.0"><link rel=stylesheet href=https://blog.llvm.org/css/normalize.min.css><link rel=stylesheet href=https://blog.llvm.org/fontawesome/css/all.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto+Slab|Ruda"><link rel=stylesheet type=text/css href=https://blog.llvm.org/css/styles.css></head><body><div id=container><header><h1><a href=https://blog.llvm.org/>The LLVM Project Blog</a></h1><ul id=social-media><li><a href=https://www.facebook.com/llvmorg title=Facebook><i class="fab fa-facebook fa-lg"></i></a></li><li><a href=https://github.com/llvm title=GitHub><i class="fab fa-github fa-lg"></i></a></li><li><a href=https://twitter.com/llvmorg title=Twitter><i class="fab fa-twitter fa-lg"></i></a></li><li><a href=https://www.youtube.com/c/LLVMPROJ title=Youtube><i class="fab fa-youtube fa-lg"></i></a></li></ul><p><em>LLVM Project News and Details from the Trenches</em></p></header><nav><ul><li><a href=https://blog.llvm.org/about><i class="fa-li fa fa-lg"></i><span>About</span></a></li><li><a href=https://blog.llvm.org/posts><i class="fa-li fa fa-lg"></i><span>Posts</span></a></li><li><a href=https://blog.llvm.org/tags><i class="fa-li fa fa-lg"></i><span>Tags</span></a></li><li><a href=https://llvm.org/><i class="fa-li fa fa-lg"></i><span>llvm.org</span></a></li></ul></nav><main><article><h1>Kaleidoscope Performance with MCJIT</h1><aside><ul><li>By Andy Kaylor</li><li><time class=post-date datetime=2013-07-29T12:11:00Z>Jul 29, 2013</time></li><li><em><a href=https://blog.llvm.org/tags/mc>#MC</a>
,
<a href=https://blog.llvm.org/tags/jit>#jit</a></em></li><li>13 minute read</li></ul></aside>In a previous post I described the process of porting the LLVM Kaleidoscope tutorial program to use MCJIT as its execution engine. &nbsp;After navigating through a serious of road blocks we ended up with an implementation that was working as expected.<br><br>So it works, but the next question is, “Is it any good?”<br><br>A lot of people considering the transition from the older JIT execution engine to MCJIT have concerns about the possible performance implications, particularly related to the fact that MCJIT doesn’t support lazy compilation. &nbsp;The older JIT engine will generate code for functions in an LLVM module one function at a time, delaying compilation of each function until it is about to be executed. &nbsp;The MCJIT engine operates on entire modules, generating code for all functions in a module at once. &nbsp;In the previous post, we modified the Kaleidoscope interpreter to create multiple modules as needed, but we’re still compiling the entire current module when a function is executed.<br><br>So what does that look like in terms of performance?<br><a name=more></a><br>The Kaleidoscope interpreter operates on input from stdin. &nbsp;When you’re sitting at your keyboard typing functions and expressions, it seems perfectly responsive. &nbsp;It would take a lot of typing to create a module large enough to have a noticeable compilation time. &nbsp;Of course, we can also drive our interpreter by redirecting a file through stdin. &nbsp;This will be useful for measuring performance. &nbsp;Unfortunately, there aren’t a lot of large Kaleidoscope programs available that we can use as a benchmark.<br><br>Instead I wrote a Python script that will generate random Kaleidoscope functions and expressions. &nbsp;By varying a few script parameters you can change the characteristics of the generated Kaleidoscope script to simulate various workload scenarios (number of functions, operations per function, number of function definitions between execution and percentage of calls within functions). &nbsp;My Python script also generates a bash script that uses the Linux ‘time’ utility to get some crude performance and memory usage measurements. &nbsp;These results should not in any way be confused with accurate benchmark data, but they ought to at least give us a rough idea of where we are.<br><br>I made some minor changes to add a divide operator and a new output function (printlf) and to eliminate unnecessary output to stderr so that we aren’t timing the ‘dump’ functions.<br><br>Here’s how my new MCJIT-based toy compares to a version built with the older JIT engine:<br><br><div class=separator style=clear:both;text-align:center><a href=http://4.bp.blogspot.com/-N9hwOu6Jbfw/Ue2Atl--6gI/AAAAAAAABNY/6-joqx1C12Y/s1600/InitialTiming.jpg imageanchor=1 style=margin-left:1em;margin-right:1em><img border=0 src=http://4.bp.blogspot.com/-N9hwOu6Jbfw/Ue2Atl--6gI/AAAAAAAABNY/6-joqx1C12Y/s1600/InitialTiming.jpg></a></div><br>The numbers across the bottom here give some indication of the input being used. &nbsp;The first number is the number of functions in the script, the second number is the number of functions called at least once and the third number is the total number of calls that will be executed.<br><br>So it turns out that depending on the input the MCJIT version of the Kaleidoscope interpreter that we’ve created is anywhere between 1.25 and 5.5 times slower. &nbsp;That’s disappointing but not really unexpected. &nbsp;Remember that the JIT version never compiles functions that aren’t used, and that’s really the weakness that this comparison was intending to quantify. &nbsp;The more functions are called, the closer our MCJIT version is to the JIT version, which is what we’d expect.<br><br>We’ll talk about memory use later, but for now let’s just say that it follows a similar pattern.<br>The input sets I have are pretty trivial, so the actual code generated isn’t particularly interesting for performance analysis. &nbsp;I can tell you from experience that where both engines are able to use the same processor features they generate nearly identical code. &nbsp;(There’s a lot shared under the hood.) &nbsp;There are some new processor features that aren’t supported by the older JIT engine, but that’s not relevant for our current comparison.<br><h3>Making MCJIT Lazy</h3>Now that we have some idea of what we’re up against, let’s turn to the task of making a version of the MCJIT toy that attempts to mimic the lazy-compilation mode of the old JIT engine. &nbsp;In the version we’ve created to this point we’re delaying creation of our execution engine until something needs to be executed, but when we do compile we’re compiling everything in the Module, not just the functions that will be executed. &nbsp;That’s an inherent part of MCJIT’s design, so to get around it, we’re going to have to create a new module for each function and put off compiling each module until it is needed for linking. &nbsp;If you had a detailed knowledge of the code you’re compiling you could optimize function grouping, putting related functions together in a module and so forth, but for the current experiment we’ll take the most general approach possible.<br><br>Once again, this is easier than you might expect.<br><br>Let’s start by moving the code that compiles a module into a new method in MCJITHelper().<br><blockquote class=tr_bq><span style="font-family:Courier New,Courier,monospace">ExecutionEngine *MCJITHelper::compileModule(Module *M) {</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; std::string ErrStr;</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; ExecutionEngine *NewEngine = EngineBuilder(M)</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .setErrorStr(&amp;ErrStr)</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .setUseMCJIT(true)</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .setMCJITMemoryManager(new HelpingMemoryManager(this))</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .create();</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; if (!NewEngine) {</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; fprintf(stderr, "Could not create ExecutionEngine: %s\n", ErrStr.c_str());</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; exit(1);</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; }</span><br><span style="font-family:Courier New,Courier,monospace"><br></span><span style="font-family:Courier New,Courier,monospace">&nbsp; // Create a function pass manager for this engine</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; FunctionPassManager *FPM = new FunctionPassManager(M);</span><br><span style="font-family:Courier New,Courier,monospace"><br></span><span style="font-family:Courier New,Courier,monospace">&nbsp; // Set up the optimizer pipeline. &nbsp;Start with registering info about how the</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; // target lays out data structures.</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; FPM->add(new DataLayout(*NewEngine->getDataLayout()));</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; // Provide basic AliasAnalysis support for GVN.</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; FPM->add(createBasicAliasAnalysisPass());</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; // Promote allocas to registers.</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; FPM->add(createPromoteMemoryToRegisterPass());</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; // Do simple "peephole" optimizations and bit-twiddling optzns.</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; FPM->add(createInstructionCombiningPass());</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; // Reassociate expressions.</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; FPM->add(createReassociatePass());</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; // Eliminate Common SubExpressions.</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; FPM->add(createGVNPass());</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; // Simplify the control flow graph (deleting unreachable blocks, etc).</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; FPM->add(createCFGSimplificationPass());</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; FPM->doInitialization();</span><br><span style="font-family:Courier New,Courier,monospace"><br></span><span style="font-family:Courier New,Courier,monospace">&nbsp; // For each function in the module</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; Module::iterator it;</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; Module::iterator end = M->end();</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; for (it = M->begin(); it != end; ++it) {</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; // Run the FPM on this function</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; FPM->run(*it);</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; }</span><br><span style="font-family:Courier New,Courier,monospace"><br></span><span style="font-family:Courier New,Courier,monospace">&nbsp; // We don't need this anymore</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; delete FPM;</span><br><span style="font-family:Courier New,Courier,monospace"><br></span><span style="font-family:Courier New,Courier,monospace">&nbsp; Engines.push_back(NewEngine);</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; NewEngine->finalizeObject();</span><br><span style="font-family:Courier New,Courier,monospace"><br></span><span style="font-family:Courier New,Courier,monospace">&nbsp; return NewEngine;</span><br><span style="font-family:Courier New,Courier,monospace">}</span></blockquote>Now the code in MCJITHelper::getPointerToFunction() that compiles the current module will look like this:<br><blockquote class=tr_bq><span style="font-family:Courier New,Courier,monospace">// If we didn't find the function, see if we can generate it.</span><br><span style="font-family:Courier New,Courier,monospace">if (OpenModule) {</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; ExecutionEngine * NewEngine = compileModule(OpenModule);</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; return NewEngine->getPointerToFunction(F);</span><br><span style="font-family:Courier New,Courier,monospace">}</span></blockquote>It will also be helpful to have a function that ‘closes’ the current module.<br><blockquote class=tr_bq><span style="font-family:Courier New,Courier,monospace">void MCJITHelper::closeCurrentModule() {</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; OpenModule = NULL;</span><br><span style="font-family:Courier New,Courier,monospace">}</span></blockquote>We don’t want to call this from MCJITHelper::getModuleForNewFunction as you might expect, because that is called for immediate expressions as well as function definitions. &nbsp;Instead, we’ll call it from the beginning of HandleDefinition(). &nbsp;This will cause the current module to be closed each time a function with a body is defined, but will still allow immediate expressions to be included in the last open module. &nbsp;We also need to call closeCurrentModule from compileModule if the module being compiled is the current module in order to handle the case of two consecutive immediate expressions.<br><br>So far so good, but the problem we now face is that our current implementation of MCJITHelper::getPointerToFunction() and MCJITHelper::getPointerToNamedFunction() both assume that they will find all functions either in the current open module or an execution engine that has already been used to compile a module.<br><br>To fix that we’ll need to change our data structures. &nbsp;Instead of keeping a vector of modules and a vector of execution engines, we’ll use a map that correlates module pointers with execution engine pointers. &nbsp;If a module has no execution engine pointer in the map that will mean the module has not yet been compiled.<br><br>In our helper class definition, we replace this:<br><blockquote class=tr_bq><span style="font-family:Courier New,Courier,monospace">typedef std::vector&lt;ExecutionEngine*> EngineVector;</span><br><span style="font-family:Courier New,Courier,monospace">EngineVector &nbsp;Engines;</span></blockquote>with this:<br><blockquote class=tr_bq><span style="font-family:Courier New,Courier,monospace">std::map&lt;Module *, ExecutionEngine *> EngineMap;</span></blockquote>And with that we can re-write our getPointerToFunction methods to look like this:<br><blockquote class=tr_bq><span style="font-family:Courier New,Courier,monospace">void *MCJITHelper::getPointerToFunction(Function* F) {</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; // Look for this function in an existing module</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; ModuleVector::iterator begin = Modules.begin();</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; ModuleVector::iterator end = Modules.end();</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; ModuleVector::iterator it;</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; std::string FnName = F->getName();</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; for (it = begin; it != end; ++it) {</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; Function *MF = (*it)->getFunction(FnName);</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; if (MF == F) {</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; std::map&lt;Module*, ExecutionEngine*>::iterator eeIt = EngineMap.find(*it);</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; if (eeIt != EngineMap.end()) {</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; &nbsp; void *P = eeIt->second->getPointerToFunction(F);</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; &nbsp; if (P)</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return P;</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; } else {</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; &nbsp; ExecutionEngine *EE = compileModule(*it);</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; &nbsp; void *P = EE->getPointerToFunction(F);</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; &nbsp; if (P)</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return P;</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; }</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; }</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; }</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; return NULL;</span><br><span style="font-family:Courier New,Courier,monospace">}</span><br><span style="font-family:Courier New,Courier,monospace"><br></span><span style="font-family:Courier New,Courier,monospace">void *MCJITHelper::getPointerToNamedFunction(const std::string &amp;Name)</span><br><span style="font-family:Courier New,Courier,monospace">{</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; // Look for the functions in our modules, compiling only as necessary</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; ModuleVector::iterator begin = Modules.begin();</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; ModuleVector::iterator end = Modules.end();</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; ModuleVector::iterator it;</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; for (it = begin; it != end; ++it) {</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; Function *F = (*it)->getFunction(Name);</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; if (F && !F->empty()) {</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; std::map&lt;Module*, ExecutionEngine*>::iterator eeIt = EngineMap.find(*it);</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; if (eeIt != EngineMap.end()) {</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; &nbsp; void *P = eeIt->second->getPointerToFunction(F);</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; &nbsp; if (P)</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return P;</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; } else {</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; &nbsp; ExecutionEngine *EE = compileModule(*it);</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; &nbsp; void *P = EE->getPointerToFunction(F);</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; &nbsp; if (P)</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return P;</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; }</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; }</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; }</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; return NULL;</span><br><span style="font-family:Courier New,Courier,monospace">}</span></blockquote>Both of these functions work in the same way. &nbsp;They iterate through our vector of Modules looking for a Module that contains a function with the name we are looking for. &nbsp;In the first case, we also check to see if this is exactly the function we’re looking for. &nbsp;(It might be a prototype.) &nbsp;Once we’ve found the right module, we check to see if the module has a corresponding execution engine. &nbsp;If it does, we ask that engine for a pointer to the function. &nbsp;If not, we compile the module and then ask the new execution engine for the pointer. &nbsp;This leaves modules in an uncompiled state until we need a function either for execution or to satisfy a linking request.<br><br>You’ll notice that this code doesn’t populate the EngineMap. &nbsp;We’ll do that in the compileModule() function instead, where we were previously adding the new engine to the Engines vector. &nbsp;We’ll also need to change our clean up code in the MCJITHelper destructor.<br><blockquote class=tr_bq><span style="font-family:Courier New,Courier,monospace">MCJITHelper::~MCJITHelper()</span><br><span style="font-family:Courier New,Courier,monospace">{</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; // Walk the vector of modules.</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; ModuleVector::iterator it, end;</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; for (it = Modules.begin(), end = Modules.end();</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; &nbsp;it != end; ++it) {</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; // See if we have an execution engine for this module.</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; std::map&lt;Module*, ExecutionEngine*>::iterator mapIt = EngineMap.find(*it);</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; // If we have an EE, the EE owns the module so just delete the EE.</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; if (mapIt != EngineMap.end()) {</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; delete mapIt->second;</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; } else {</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; // Otherwise, we still own the module. &nbsp;Delete it now.</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; &nbsp; delete *it;</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; &nbsp; }</span><br><span style="font-family:Courier New,Courier,monospace">&nbsp; }</span><br><span style="font-family:Courier New,Courier,monospace">}</span></blockquote>Note that once a module has been passed to an execution engine, the execution engine owns that module, so in each case we only need to delete a module or an execution engine, but never both.<br><h3>Lazy Performance Analysis</h3>At this point, the MCJIT-based version of our Kaleidoscope interpreter should be compiling lazily just like the old JIT-based implementation did. &nbsp;Let’s re-run our test workloads and see how it stacks up.<br><br>Here are the new results.<br><br><div class=separator style=clear:both;text-align:center><a href=http://1.bp.blogspot.com/-2iD8rrxxxQI/Ue2A6LTlKlI/AAAAAAAABNg/5VPeiEOLVv0/s1600/LazyTiming.jpg imageanchor=1 style=margin-left:1em;margin-right:1em><img border=0 src=http://1.bp.blogspot.com/-2iD8rrxxxQI/Ue2A6LTlKlI/AAAAAAAABNg/5VPeiEOLVv0/s1600/LazyTiming.jpg></a></div><br>That looks quite a bit better. &nbsp;The big spike in the fourth column is the case where each function is called immediately after it is defined. &nbsp;The MCJIT implementation is still about 1.3 times slower with 5000 functions in that case, but previously that was one of the better points of comparison for MCJIT. &nbsp;Now it’s the worst case scenario.<br><br>Also notice that with the new “lazy” MCJIT implementation there are a few cases where our MCJIT-based interpreter is quicker than the old JIT-based implementation.<br><h3>Memory Consumption</h3>Now let’s talk about memory usage. &nbsp;You can probably see without measurements that our new “lazy” implementation is going to consume more memory than the old implementation. &nbsp;We’re creating a new Module instance for each and every function that gets defined and a bunch more execution engine related objects every time one of these things gets compiled. &nbsp;But how bad is it?<br><br>It’s bad. &nbsp;I’m not sure how far to trust the memory statistics I’m getting from the time utility, but assuming they at least reliable enough to be a rough guide the MCJIT implementation has some issues. &nbsp;In the cases where the MCJIT implementation has a performance advantage the memory consumption can be as little as 1.5 times the JIT implementation, but in the worst case scenario of each function being called immediately after it is defined the MCJIT implementation can take up to 10 times more memory than the JIT implementation.<br><br>What are we to make of this? &nbsp;Well, let’s start with a sanity check. &nbsp;As the introduction to the Kaleidoscope tutorial says the tutorial isn’t meant to be a good implementation -- “the code leaks memory, uses global variables all over the place, doesn’t use nice design patterns like visitors, etc... but it is very simple.”<br>There are some very basic things going on that waste a lot of memory, and those are amplified in our MCJIT implementation. &nbsp;For instance, when an immediate expression is used, we leave it in memory for the duration of program execution, even though we can be absolutely certain we’ll never reference it again.<br><br>Also, I don’t really have a feel for whether or not the sample inputs I’m using have any correspondence to a real world usage pattern. &nbsp;I haven’t done a detailed analysis of memory use, but at first glance it appears that a large chunk of the memory is being used to generate relocation tables for each generated object image. &nbsp;In theory we could drop those tables as soon as the object is fixed in memory (that is, after the call to finalizeObject), but we don’t. &nbsp;This problem is magnified by the fact that the workloads are heavily based on a network of random calls between functions, probably involving a disproportionately high number of cross module references. &nbsp;I’ve made no attempt to optimize that.<br><br>As I said, I just generated a bunch of random code and threw it at the interpreter. &nbsp;That’s true of the performance numbers too, of course. &nbsp;Remember, my goal here was just to try to get a ballpark feel for what the implementation looked like.<br><br>My ballpark feel is that with the “lazy” implementation the performance is going to be just about as good as the old JIT implementation, but it’s going to use more memory.<br><h3>Next Steps</h3>So what else can we do with this? &nbsp;Why would anyone want to go to the trouble of switching to MCJIT just to get something that performed just about as well but used more memory?<br><br>I could say that you’ll get better ongoing support and adoption of new LLVM enhancements with MCJIT. &nbsp;While that’s true, it would probably leave you a bit frustrated.<br><br>Instead, what I’m going to tell you is that MCJIT has a great feature that will give it a huge leg up on the old JIT engine in many real world usage scenarios. &nbsp;But that’s going to have to wait until my next post….<br><br>The full source code listing for this post along with the scripts for generating test input are available in the trunk of the LLVM source tree at &lt;llvm_root>/examples/Kaleidoscope/MCJIT.<br><div><br></div></article><section class=post-nav><ul><li><a href=https://blog.llvm.org/2013/07/using-mcjit-with-kaleidoscope-tutorial.html><i class="fa fa-chevron-circle-left"></i> Using MCJIT with the Kaleidoscope Tutorial</a></li><li><a href=https://blog.llvm.org/2013/08/object-caching-with-kaleidoscope.html>Object Caching with the Kaleidoscope Example Program <i class="fa fa-chevron-circle-right"></i></a></li></ul></section></main><footer><ul><li><h6>llvm.org |
Rendered by <a href=https://gohugo.io title=Hugo>Hugo</a> |
<a href=https://blog.llvm.org/index.xml>Subscribe</a></h6></li></ul></footer></div><script src=https://blog.llvm.org/js/scripts.js></script></body></html>