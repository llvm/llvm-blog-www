---
author: Andy Kaylor
blogger_id: tag:blogger.com,1999:blog-6088150582281556517.post-9159707904989854074
blogger_orig_url: http://blog.llvm.org/2013/08/object-caching-with-kaleidoscope.html
date: "2013-08-02T11:00:00Z"
modified_time: "2013-08-02T11:00:14.708-07:00"
tags: ["MC","jit"]
thumbnail: http://4.bp.blogspot.com/-XE698SRqneI/Ue228waFk_I/AAAAAAAABNs/nYc00U-dfCs/s72-c/CacheTiming.jpg
title: Object Caching with the Kaleidoscope Example Program
---

In previous posts I described the process of porting the LLVM Kaleidoscope tutorial program to use MCJIT as its execution engine and introduced a lazy compilation implementation with the MCJIT engine. &nbsp;The lazy implementation produced similar, and in some cases better, performance when compared with an implementation based on the older JIT execution engine, but it used more memory.<br /><br />In this post, I’m going to extend the new implementation to use MCJIT’s object caching interface. &nbsp;This will give our interpreter a way to store pre-compiled versions of previously used function and retrieve them for execution in later runs of the program.<br /><a name='more'></a><br /><h3>Adding a Library Parsing Mechanism</h3>I’m going to base the object caching on a library loading model. &nbsp;In theory we could cache any object that the execution engine generates, but to make effective use of the cache we need some way of knowing that what we’re loading matches something we previously stored. &nbsp;For simplicity, I’m going to extend the Kaleidoscope tutorial to accept a command line argument that references an LLVM IR file to be loaded as a library. &nbsp;Once that’s working, I’ll introduce the object caching mechanism.<br /><br />The IR loading is a fairly easy thing to add. &nbsp;We’ll use a standard LLVM command line parsing template:<br /><blockquote class="tr_bq"><span style="font-family: Courier New, Courier, monospace;">cl::opt&lt;std::string&gt;</span><br /><span style="font-family: Courier New, Courier, monospace;">InputIR("input-IR",</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; &nbsp; cl::desc("Specify the name of an IR file to load for function definitions"),</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; &nbsp; cl::value_desc("input IR file name"));</span></blockquote>Then in the main() function, we’ll add argc and argv parameters along with a call to parse the command line options.<br /><blockquote class="tr_bq"><span style="font-family: Courier New, Courier, monospace;">int main(int argc, char **argv) {</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; InitializeNativeTarget();</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; InitializeNativeTargetAsmPrinter();</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; InitializeNativeTargetAsmParser();</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; LLVMContext &amp;Context = getGlobalContext();</span><br /><span style="font-family: Courier New, Courier, monospace;"><br /></span> <span style="font-family: Courier New, Courier, monospace;">&nbsp; cl::ParseCommandLineOptions(argc, argv,</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "Kaleidoscope example program\n");</span><br /><span style="font-family: Courier New, Courier, monospace;"><br /></span> <span style="font-family: Courier New, Courier, monospace;">&nbsp; if (!InputIR.empty()) {</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; parseInputIR(InputIR);</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; }</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; ...</span><br /><span style="font-family: Courier New, Courier, monospace;">}</span></blockquote>Happily, LLVM also gives us what we need to parse an IR file into a module:<br /><blockquote class="tr_bq"><span style="font-family: Courier New, Courier, monospace;">bool parseInputIR(std::string InputFile) {</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; SMDiagnostic Err;</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; Module *M = ParseIRFile(InputFile, Err, getGlobalContext());</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; if (!M) {</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; Err.print("IR parsing failed: ", errs());</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; return false;</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; }</span><br /><span style="font-family: Courier New, Courier, monospace;"><br /></span> <span style="font-family: Courier New, Courier, monospace;">&nbsp; char ModID[256];</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; sprintf(ModID, "IR:%s", InputFile.c_str());</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; M-&gt;setModuleIdentifier(ModID);</span><br /><span style="font-family: Courier New, Courier, monospace;"><br /></span> <span style="font-family: Courier New, Courier, monospace;">&nbsp; TheHelper-&gt;addModule(M);</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; return true; &nbsp; &nbsp;</span><br /><span style="font-family: Courier New, Courier, monospace;">}</span></blockquote>I’m setting an identifier that we can use to recognize that this module was loaded as an IR file. &nbsp;We’ll use that later for object caching, but right now it also lets us skip the function optimization passes when we compile this module.<br /><blockquote class="tr_bq"><span style="font-family: Courier New, Courier, monospace;">// Get the ModuleID so we can identify IR input files</span><br /><span style="font-family: Courier New, Courier, monospace;">const std::string ModuleID = M-&gt;getModuleIdentifier();</span><br /><span style="font-family: Courier New, Courier, monospace;"><br /></span> <span style="font-family: Courier New, Courier, monospace;">// If we've flagged this as an IR file, it doesn't need function passes run.</span><br /><span style="font-family: Courier New, Courier, monospace;">if (0 != ModuleID.compare(0, 3, "IR:")) {</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; // Create a function pass manager for this engine</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; FunctionPassManager *FPM = new FunctionPassManager(M);</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; ...</span><br /><span style="font-family: Courier New, Courier, monospace;">}</span></blockquote>Finally, we need to provide a function to add the newly created module to the list of modules handled by MCJITHelper.<br /><blockquote class="tr_bq"><span style="font-family: Courier New, Courier, monospace;">void MCJITHelper::addModule(Module* M) {</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; Modules.push_back(M);</span><br /><span style="font-family: Courier New, Courier, monospace;">}</span></blockquote>Our lazy compilation mechanism will take care of compiling this module when any function it contains is called.<br /><br />When we build the program now, we need to add ‘irreader’ to the list of libraries on the compile line.<br /><br />At this point, we can provide a complete IR file as input to our Kaleidoscope interpreter. &nbsp;You can generate an IR file by capturing the ‘dump’ output of a module that has been created by our interpreter. &nbsp;It’s easiest to do this using the old JIT-based implementation, since it keeps everything in one module. &nbsp;Because the particulars of where an input file will come from are likely to be implementation specific, I’ll just leave it at that for now.<br /><h3>Implementing Object Cache</h3>The mechanism above to load IR files can be used with either the JIT or MCJIT implementations of the Kaleidoscope interpreter. &nbsp;With the MCJIT implementation, there is a significant time hit for compilation the first time a library is accessed, but subsequent references will be very fast. &nbsp;With the JIT implementation, the module parsed from IR is compiled lazily and so its responsiveness will be more uniform.<br /><br />However, MCJIT provides a mechanism for caching generated object images. &nbsp;Once we’ve compiled a module, we can store the image and never have to compile it again. &nbsp;This is not available with the JIT execution engine and gives MCJIT a significant performance advantage when a library is used in multiple invocations of the program.<br /><br />MCJIT uses a callback mechanism to allow clients to register a custom cache handler. &nbsp;The handler must be a subclass of the ObjectCache class defined in ‘llvm/ExecutionEngine/ObjectCache.h.” &nbsp;For this example, I’m going to use a very simple scheme that uses the input IR filename as a key and stores cached files in a subdirectory relative to the current working directory. &nbsp;Obviously in a real product you’d want something more sophisticated, but for demonstration purposes this will work.<br /><br />Here’s the implementation:<br /><blockquote class="tr_bq"><span style="font-family: Courier New, Courier, monospace;">//===----------------------------------------------------------------------===//</span><br /><span style="font-family: Courier New, Courier, monospace;">// MCJIT object cache class</span><br /><span style="font-family: Courier New, Courier, monospace;">//===----------------------------------------------------------------------===//</span><br /><span style="font-family: Courier New, Courier, monospace;"><br /></span> <span style="font-family: Courier New, Courier, monospace;">class MCJITObjectCache : public ObjectCache {</span><br /><span style="font-family: Courier New, Courier, monospace;">public:</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; MCJITObjectCache() {</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; // Set IR cache directory</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; sys::fs::current_path(CacheDir);</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; sys::path::append(CacheDir, "toy_object_cache");</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; }</span><br /><span style="font-family: Courier New, Courier, monospace;"><br /></span> <span style="font-family: Courier New, Courier, monospace;">&nbsp; virtual ~MCJITObjectCache() {</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; }</span><br /><span style="font-family: Courier New, Courier, monospace;"><br /></span> <span style="font-family: Courier New, Courier, monospace;">&nbsp; virtual void notifyObjectCompiled(const Module *M, const MemoryBuffer *Obj) {</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; // Get the ModuleID</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; const std::string ModuleID = M-&gt;getModuleIdentifier();</span><br /><span style="font-family: Courier New, Courier, monospace;"><br /></span> <span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; // If we've flagged this as an IR file, cache it</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; if (0 == ModuleID.compare(0, 3, "IR:")) {</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; std::string IRFileName = ModuleID.substr(3);</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; SmallString&lt;128&gt;IRCacheFile = CacheDir;</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; sys::path::append(IRCacheFile, IRFileName);</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; if (!sys::fs::exists(CacheDir.str()) &amp;&amp; sys::fs::create_directory(CacheDir.str())) {</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; &nbsp; fprintf(stderr, "Unable to create cache directory\n");</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; &nbsp; return;</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; }</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; std::string ErrStr;</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; raw_fd_ostream IRObjectFile(IRCacheFile.c_str(), ErrStr, raw_fd_ostream::F_Binary);</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; IRObjectFile &lt;&lt; Obj-&gt;getBuffer();</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; }</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; }</span><br /><span style="font-family: Courier New, Courier, monospace;"><br /></span> <span style="font-family: Courier New, Courier, monospace;">&nbsp; // MCJIT will call this function before compiling any module</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; // MCJIT takes ownership of both the MemoryBuffer object and the memory</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; // to which it refers.</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; virtual MemoryBuffer* getObject(const Module* M) {</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; // Get the ModuleID</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; const std::string ModuleID = M-&gt;getModuleIdentifier();</span><br /><span style="font-family: Courier New, Courier, monospace;"><br /></span> <span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; // If we've flagged this as an IR file, cache it</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; if (0 == ModuleID.compare(0, 3, "IR:")) {</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; std::string IRFileName = ModuleID.substr(3);</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; SmallString&lt;128&gt; IRCacheFile = CacheDir;</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; sys::path::append(IRCacheFile, IRFileName);</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; if (!sys::fs::exists(IRCacheFile.str())) {</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; &nbsp; // This file isn't in our cache</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; &nbsp; return NULL;</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; }</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; OwningPtr&lt;MemoryBuffer&gt; IRObjectBuffer;</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; MemoryBuffer::getFile(IRCacheFile.c_str(), IRObjectBuffer, -1, false);</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; // MCJIT will want to write into this buffer, and we don't want that</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; // because the file has probably just been mmapped. &nbsp;Instead we make</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; // a copy. &nbsp;The filed-based buffer will be released when it goes</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; // out of scope.</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; return MemoryBuffer::getMemBufferCopy(IRObjectBuffer-&gt;getBuffer());</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; }</span><br /><span style="font-family: Courier New, Courier, monospace;"><br /></span> <span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; return NULL;</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; }</span><br /><span style="font-family: Courier New, Courier, monospace;"><br /></span> <span style="font-family: Courier New, Courier, monospace;">private:</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; SmallString&lt;128&gt; CacheDir;</span><br /><span style="font-family: Courier New, Courier, monospace;">};</span></blockquote>I’m going to instantiate this cache as a member variable of the MCJITHelper class. &nbsp;I’m also adding a command line option to enable cache use.<br /><blockquote class="tr_bq"><span style="font-family: Courier New, Courier, monospace;">cl::opt&lt;bool&gt;&nbsp;</span><br /><span style="font-family: Courier New, Courier, monospace;">UseObjectCache("use-object-cache",&nbsp;</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;cl::desc("Enable use of the MCJIT object caching"),</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;cl::init(false));</span></blockquote>Activating the cache simply requires a single call to the ExecutionEngine object after it has been created in MCJITHelper::compileModule():<br /><blockquote class="tr_bq"><span style="font-family: Courier New, Courier, monospace;">if (UseObjectCache)</span><br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; NewEngine-&gt;setObjectCache(&amp;OurObjectCache);</span></blockquote>At this point the MCJIT engine itself manages use of the cache. &nbsp;When the MCJIT engine is about to compile a module, it will call the cache’s getObject method. &nbsp;If this method returns an object image, MCJIT will prepare that object for execution rather than compiling a new version. &nbsp;When MCJIT does compile a module it calls the cache’s NotifyObjectCompiled method, giving the cache a chance to store the object image.<br /><br />The implementation above uses the Module identifier as a key to identify matching modules, but clients are free to use any mechanism to make this identification.<br /><h3>Cache Performance</h3>Now that we have the object caching mechanism in place, let’s take a look and see how it impacts our performance.<br /><br />I’ve created a new set of test inputs based on the inputs I used for previous measurements, but I separated the function definitions and the immediate function calls into separate script files and then generated an IR file from the function definitions. &nbsp;I’ll use these files to execute a workload that is equivalent to the previous workload while using an IR input file and loading the resultant object from cache when possible.<br /><br />There is obviously some performance benefit just from having a ready-made IR file rather than having to parse Kaleidoscope input, so I also created a version of the JIT-based implementation which accepts the IR input library to provide a meaningful point of comparison.<br /><br />The chart below shows the 5000-function workloads I’ve been using run with multiple implementations of the Kaleidoscope interpreter. &nbsp;The first three bars in each group show the “lazy” MCJIT implementation, the original JIT implementation and our first working MCJIT implementation with the original workload file. &nbsp;The next three bars show the new implementations using an IR input file for function definitions.<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-XE698SRqneI/Ue228waFk_I/AAAAAAAABNs/nYc00U-dfCs/s1600/CacheTiming.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://4.bp.blogspot.com/-XE698SRqneI/Ue228waFk_I/AAAAAAAABNs/nYc00U-dfCs/s1600/CacheTiming.jpg" /></a></div><br />As you can see, the non-cached run of the library-based MCJIT implementation is slightly faster than our first working implementation (because the IR is pre-made), but significantly slower than the “lazy” MCJIT implementation. &nbsp;However, this performance hit is only incurred the first time the workload is run. &nbsp;When the workload is run with this same MCJIT implementation a second time the function library is loaded from cache and the performance is far and away better than any of the other implementations.<br /><h3>Conclusions</h3>So where does this leave us? &nbsp;Did you ever have one of those math professors in college who would get halfway through a tricky proof and then write “QED” on the board even though it wasn’t at all obvious how he would finish it? &nbsp;That’s the part we’re at now.<br /><br />I began this exercise in an attempt to either prove or disprove that the MCJIT execution engine was suitable for use in a program that relied on true just-in-time compilation. &nbsp;I came up with a reference implementation that does that, though with a few lingering questions – particularly regarding memory consumption.<br /><br />At this point, I’m satisfied that MCJIT is up to the task. &nbsp;<i>Quod erat demonstratum</i>.<br /><br />Of course, there’s more work to be done. &nbsp;Any serious implementation using the techniques I’ve shown would require a lot of fine tuning. &nbsp;Some of what I’ve done, such as the multiple module management, can and should be moved into the MCJIT component itself. &nbsp;No doubt many of the opportunities for performance improvements and more efficient memory use will also be within the MCJIT component. &nbsp;Nevertheless, I think the way forward is reasonably well defined.<br /><br />Several active LLVM developers are committed to making MCJIT a top notch execution engine. &nbsp;I hope that the exploration I’ve presented here will help more developers make use of it now and will generate momentum to iron out whatever additional shortcomings remain.<br /><br />The full source code listing for this post along with the scripts for generating test input are available in the trunk of the LLVM source tree at &lt;llvm_root&gt;/examples/Kaleidoscope/MCJIT.
