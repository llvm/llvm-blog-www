<!doctype html><html lang=en><head><title>Life of an instruction in LLVM - The LLVM Project Blog</title>
<meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="LLVM Project News and Details from the Trenches"><meta name=author content="Eli Bendersky"><meta property="og:url" content="https://blog.llvm.org/2012/11/life-of-instruction-in-llvm.html"><meta property="og:site_name" content="The LLVM Project Blog"><meta property="og:title" content="Life of an instruction in LLVM"><meta property="og:description" content="LLVM is a complex piece of software. There are several paths one may take on the quest of understanding how it works, none of which is simple. I recently had to dig in some areas of LLVM I was not previously familiar with, and this article is one of the outcomes of this quest."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2012-11-28T15:31:00+00:00"><meta property="article:modified_time" content="2012-11-28T15:31:00+00:00"><meta property="article:tag" content="CodeGen"><meta property="article:tag" content="MC"><meta property="article:tag" content="Clang"><meta property="article:tag" content="SelectionDAG"><meta property="article:tag" content="LLVM-IR"><meta name=twitter:card content="summary"><meta name=twitter:title content="Life of an instruction in LLVM"><meta name=twitter:description content="LLVM is a complex piece of software. There are several paths one may take on the quest of understanding how it works, none of which is simple. I recently had to dig in some areas of LLVM I was not previously familiar with, and this article is one of the outcomes of this quest."><meta name=generator content="Hugo 0.128.0"><link rel=stylesheet href=https://blog.llvm.org/css/normalize.min.css><link rel=stylesheet href=https://blog.llvm.org/fontawesome/css/all.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto+Slab|Ruda"><link rel=stylesheet type=text/css href=https://blog.llvm.org/css/styles.css></head><body><div id=container><header><h1><a href=https://blog.llvm.org/>The LLVM Project Blog</a></h1><ul id=social-media><li><a href=https://www.facebook.com/llvmorg title=Facebook><i class="fab fa-facebook fa-lg"></i></a></li><li><a href=https://github.com/llvm title=GitHub><i class="fab fa-github fa-lg"></i></a></li><li><a href=https://twitter.com/llvmorg title=Twitter><i class="fab fa-twitter fa-lg"></i></a></li><li><a href=https://www.youtube.com/c/LLVMPROJ title=Youtube><i class="fab fa-youtube fa-lg"></i></a></li></ul><p><em>LLVM Project News and Details from the Trenches</em></p></header><nav><ul><li><a href=https://blog.llvm.org/about><i class="fa-li fa fa-lg"></i><span>About</span></a></li><li><a href=https://blog.llvm.org/posts><i class="fa-li fa fa-lg"></i><span>Posts</span></a></li><li><a href=https://blog.llvm.org/tags><i class="fa-li fa fa-lg"></i><span>Tags</span></a></li><li><a href=https://llvm.org/><i class="fa-li fa fa-lg"></i><span>llvm.org</span></a></li></ul></nav><main><article><h1>Life of an instruction in LLVM</h1><aside><ul><li>By Eli Bendersky</li><li><time class=post-date datetime=2012-11-28T15:31:00Z>Nov 28, 2012</time></li><li><em><a href=https://blog.llvm.org/tags/codegen>#codegen</a>
,
<a href=https://blog.llvm.org/tags/mc>#MC</a>
,
<a href=https://blog.llvm.org/tags/clang>#Clang</a>
,
<a href=https://blog.llvm.org/tags/selectiondag>#SelectionDAG</a>
,
<a href=https://blog.llvm.org/tags/llvm-ir>#LLVM-IR</a></em></li><li>12 minute read</li></ul></aside><br>LLVM is a complex piece of software. There are several paths one may take on the quest of understanding how it works, none of which is simple. I recently had to dig in some areas of LLVM I was not previously familiar with, and this article is one of the outcomes of this quest.<br><br>What I aim to do here is follow the various incarnations an "instruction" takes when it goes through LLVM’s multiple compilation stages, starting from a syntactic construct in the source language and until being encoded as binary machine code in an output object file.<br><br>This article in itself will not teach one how LLVM works. It assumes some existing familiarity with LLVM’s design and code base, and leaves a lot of "obvious" details out. Note that unless otherwise stated, the information here is relevant to LLVM 3.2. LLVM and Clang are fast-moving projects, and future changes may render parts of this article incorrect. If you notice any discrepancies, please let me know and I’ll do my best to fix them.<br><br><a name=more></a><br><div class=section id=input-code><h3>Input code</h3>I want to start this exploration process at the beginning – C source. Here’s the simple function we’re going to work with:<br><br><div class=highlight style=background:#fff><pre style=line-height:125%><span style=font-size:small><br><span style=color:#00007f;font-weight:700>int</span> <span style=color:#00007f>foo</span>(<span style=color:#00007f;font-weight:700>int</span> aa, <span style=color:#00007f;font-weight:700>int</span> bb, <span style=color:#00007f;font-weight:700>int</span> cc) {<br>  <span style=color:#00007f;font-weight:700>int</span> sum = aa + bb;<br>  <span style=color:#00007f;font-weight:700>return</span> sum / cc;<br>}</span><br></pre></div><br>The focus of this article is going to be on the division operation.</div><div class=section id=clang><h3>Clang</h3>Clang serves as the front-end for LLVM, responsible for converting C, C++ and ObjC source into LLVM IR. Clang’s main complexity comes from the ability to correctly parse and semantically analyze C++; the flow for a simple C-level operation is actually quite straightforward.<br><br>Clang’s parser builds an Abstract Syntax Tree (AST) out of the input. The AST is the main "currency" in which various parts of Clang deal. For our division operation, a <tt class="docutils literal">BinaryOperator</tt> node is created in the AST, carrying the <tt class="docutils literal">BO_div</tt> "operator kind". Clang’s code generator then goes on to emit a <tt class="docutils literal">sdiv</tt> LLVM IR instruction from the node, since this is a division of signed integral types.<br><div class=section id=llvm-ir><h3>LLVM IR</h3>Here is the LLVM IR created for the function:<br><br><div class=highlight style=background:#fff><pre style=line-height:125%>define i32 @foo(i32 %aa, i32 %bb, i32 %cc) nounwind {<br>entry:<br>  %add = add nsw i32 %aa, %bb<br>  %div = sdiv i32 %add, %cc<br>  ret i32 %div<br>}<br></pre></div><br>In LLVM IR, <tt class="docutils literal">sdiv</tt> is a <tt class="docutils literal">BinaryOperator</tt>, which is a subclass of <tt class="docutils literal">Instruction</tt> with the opcode <tt class="docutils literal">SDiv</tt>. Like any other instruction, it can be processed by the LLVM analysis and transformation passes. For a specific example targeted at <tt class="docutils literal">SDiv</tt>, take a look at <tt class="docutils literal">SimplifySDivInst</tt>. Since all through the LLVM "middle-end" layer the instruction remains in its IR form, I won’t spend much time talking about it. To witness its next incarnation, we’ll have to look at the LLVM code generator.<br><br>The code generator is one of the most complex parts of LLVM. Its task is to "lower" the relatively high-level, target-independent LLVM IR into low-level, target-dependent "machine instructions" (<tt class="docutils literal">MachineInstr</tt>). On its way to a <tt class="docutils literal">MachineInstr</tt>, an LLVM IR instruction passes through a "selection DAG node" incarnation, which is what I’m going to discuss next.</div></div><h3>SelectionDAG node</h3>Selection DAG nodes are created by the <tt class="docutils literal">SelectionDAGBuilder</tt> class acting "in the service of" <tt class="docutils literal">SelectionDAGISel</tt>, which is the main base class for instruction selection. <tt class="docutils literal">SelectionDAGISel</tt> goes over all the IR instructions and calls the <tt class="docutils literal"><span class=pre>SelectionDAGBuilder::visit</span></tt> dispatcher on them. The method handling a <tt class="docutils literal">SDiv</tt> instruction is <tt class="docutils literal"><span class=pre>SelectionDAGBuilder::visitSDiv</span></tt>. It requests a new <tt class="docutils literal">SDNode</tt> from the DAG with the opcode <tt class="docutils literal"><span class=pre>ISD::SDIV</span></tt>, which becomes a node in the DAG.<br><br>The initial DAG constructed this way is still only partially target dependent. In LLVM nomenclature it’s called "illegal" – the types it contains may not be directly supported by the target; the same is true for the operations it contains.<br><br>There are a couple of ways to visualize the DAG. One is to pass the <tt class="docutils literal"><span class=pre>-debug</span></tt> flag to <tt class="docutils literal">llc</tt>, which will cause it to create a textual dump of the DAG during all the selection phases. Another is to pass one of the <tt class="docutils literal"><span class=pre>-view</span></tt> options which causes it to dump and display an actual image of the graph (more details in the <a class="reference external" href=http://llvm.org/docs/CodeGenerator.html>code generator docs</a>). Here’s the relevant portion of the DAG showing our <tt class="docutils literal">SDiv</tt> node, right after DAG creation (the <tt class="docutils literal">sdiv</tt> node is in the bottom):<br><br><div class=separator style=clear:both;text-align:center><a href=http://2.bp.blogspot.com/-SjbbSsuPKbo/ULTDEf2o5hI/AAAAAAAAAgM/CmQd_eeGowY/s1600/sdiv_initial_dag.png imageanchor=1 style=margin-left:1em;margin-right:1em><img border=0 src=http://2.bp.blogspot.com/-SjbbSsuPKbo/ULTDEf2o5hI/AAAAAAAAAgM/CmQd_eeGowY/s1600/sdiv_initial_dag.png></a></div><br><div class=separator style=clear:both;text-align:center></div><br><br>Before the <tt class="docutils literal">SelectionDAG</tt> machinery actually emits machine instructions from DAG nodes, these undergo a few other transformations. The most important are the type and operation legalization steps, which use target-specific hooks to convert all operations and types into ones that the target actually supports.<br><h3>"Legalizing" sdiv into sdivrem on x86</h3>The division instruction (<tt class="docutils literal">idiv</tt> for signed operands) of x86 computes both the quotient and the remainder of the operation, and stores them in two separate registers. Since LLVM’s instruction selection distinguishes between such operations (called <tt class="docutils literal"><span class=pre>ISD::SDIVREM</span></tt>) and division that only computes the quotient (<tt class="docutils literal"><span class=pre>ISD::SDIV</span></tt>), our DAG node will be "legalized" during the DAG legalization phase when the target is x86. Here’s how it happens.<br><br>An important interface used by the code generator to convey target-specific information to the generally target-independent algorithms is <tt class="docutils literal">TargetLowering</tt>. Targets implement this interface to describe how LLVM IR instructions should be lowered to legal <tt class="docutils literal">SelectionDAG</tt> operations. The x86 implementation of this interface is <tt class="docutils literal">X86TargetLowering</tt>. In its constructor it marks which operations need to be "expanded" by operation legalization, and <tt class="docutils literal"><span class=pre>ISD::SDIV</span></tt> is one of them. Here’s an interesting comment from the code:<br><br><div class=highlight style=background:#fff><pre style=line-height:125%><span style=color:#007f00><br>// Scalar integer divide and remainder are lowered to use operations that</span><br><span style=color:#007f00>// produce two results, to match the available instructions. This exposes</span><br><span style=color:#007f00>// the two-result form to trivial CSE, which is able to combine x/y and x%y</span><br><span style=color:#007f00>// into a single instruction.</span><br></pre></div>&nbsp;<br>When <tt class="docutils literal"><span class=pre>SelectionDAGLegalize::LegalizeOp</span></tt> sees the <tt class="docutils literal">Expand</tt> flag on a SDIV node it replaces it by <tt class="docutils literal"><span class=pre>ISD::SDIVREM</span></tt>. This is an interesting example to demonstrate the transformation an operation can undergo while in the selection DAG form.<br><br>Here is the relevant portion of the DAG after legalization:<br><br><div class=separator style=clear:both;text-align:center><a href=http://1.bp.blogspot.com/-4Hr-DU4FbR0/ULTCadxhrgI/AAAAAAAAAgE/hzLJ9YqVdT4/s1600/sdivrem_legal_dag.png imageanchor=1 style=margin-left:1em;margin-right:1em><img border=0 src=http://1.bp.blogspot.com/-4Hr-DU4FbR0/ULTCadxhrgI/AAAAAAAAAgE/hzLJ9YqVdT4/s1600/sdivrem_legal_dag.png></a></div><br><div class=section id=instruction-selection-from-sdnode-to-machinesdnode><h3>Instruction selection – from SDNode to MachineSDNode</h3>The next step in the code generation process is <i>instruction selection</i>. LLVM provides a generic table-based instruction selection mechanism that is auto-generated with the help of TableGen. Many target backends, however, choose to write custom code in their <tt class="docutils literal"><span class=pre>SelectionDAGISel::Select</span></tt> implementations to handle some instructions manually. Other instructions are then sent to the auto-generated selector by calling <tt class="docutils literal">SelectCode</tt>.<br><br>The X86 backend handles <tt class="docutils literal"><span class=pre>ISD::SDIVREM</span></tt> manually in order to take care of some special cases and optimizations. The DAG node created at this step is a <tt class="docutils literal">MachineSDNode</tt>, a subclass of <tt class="docutils literal">SDNode</tt> which holds the information required to construct an actual machine instruction, but still in DAG node form. At this point the actual X86 instruction opcode is selected – <tt class="docutils literal"><span class=pre>X86::IDIV32r</span></tt> in our case.<br><br><div class=separator style=clear:both;text-align:center><a href=http://3.bp.blogspot.com/-odnuGpLx3EA/ULTEEYSivqI/AAAAAAAAAgU/bcQZtTPOw2c/s1600/idiv_after_isel.png imageanchor=1 style=margin-left:1em;margin-right:1em><img border=0 src=http://3.bp.blogspot.com/-odnuGpLx3EA/ULTEEYSivqI/AAAAAAAAAgU/bcQZtTPOw2c/s1600/idiv_after_isel.png></a></div></div><h3>Scheduling and emitting a MachineInstr</h3>The code we have at this point is still represented as a DAG. But CPUs don’t execute DAGs, they execute a linear sequence of instructions. The goal of the scheduling step is to linearize the DAG by assigning an order to its operations (nodes). The simplest approach would be to just sort the DAG topologically, but LLVM’s code generator employs clever heuristics (such as register pressure reduction) to try and produce a schedule that would result in faster code.<br>Each target has some hooks it can implement to affect the way scheduling is done. I won't dwell on this topic here, however.<br><br>Finally, the scheduler emits a list of instructions into a <tt class="docutils literal">MachineBasicBlock</tt>, using <tt class="docutils literal"><span class=pre>InstrEmitter::EmitMachineNode</span></tt> to translate from <tt class="docutils literal">SDNode</tt>. The instructions here take the <tt class="docutils literal">MachineInstr</tt> form ("MI form" from now on), and the DAG can be destroyed.<br>We can examine the machine instructions emitted in this step by calling <tt class="docutils literal">llc</tt> with the <tt class="docutils literal"><span class=pre>-print-machineinstrs</span></tt> flag and looking at the first output that says "After instruction selection":<br><br><pre style=line-height:125%><span style="font-family:courier new,Courier,monospace"><span style=font-size:x-small><br># After Instruction Selection:<br># Machine code for function foo: SSA<br>Function Live Ins: %EDI in %vreg0, %ESI in %vreg1, %EDX in %vreg2<br>Function Live Outs: %EAX<br><br>BB#0: derived from LLVM BB %entry<br>    Live Ins: %EDI %ESI %EDX<br>        %vreg2&lt;def&gt; = COPY %EDX; GR32:%vreg2<br>        %vreg1&lt;def&gt; = COPY %ESI; GR32:%vreg1<br>        %vreg0&lt;def&gt; = COPY %EDI; GR32:%vreg0<br>        %vreg3&lt;def,tied1&gt; = ADD32rr %vreg0&lt;tied0&gt;, %vreg1, %EFLAGS&lt;imp-def,dead&gt;; GR32:%vreg3,%vreg0,%vreg1<br>        %EAX&lt;def&gt; = COPY %vreg3; GR32:%vreg3<br>        CDQ %EAX&lt;imp-def&gt;, %EDX&lt;imp-def&gt;, %EAX&lt;imp-use&gt;<br>        IDIV32r %vreg2, %EAX&lt;imp-def&gt;, %EDX&lt;imp-def,dead&gt;, %EFLAGS&lt;imp-def,dead&gt;, %EAX&lt;imp-use&gt;, %EDX&lt;imp-use&gt;; GR32:%vreg2<br>        %vreg4&lt;def&gt; = COPY %EAX; GR32:%vreg4<br>        %EAX&lt;def&gt; = COPY %vreg4; GR32:%vreg4<br>        RET<br><br># End machine code for function foo.<br></span></span></pre><pre style=line-height:125%>&nbsp;</pre>Note that the output mentions that the code is in SSA form, and we can see that some registers being used are "virtual" registers (e.g. <tt class="docutils literal">%vreg1</tt>).<br><div class=section id=register-allocation-from-ssa-to-non-ssa-machine-instructions><h3>Register allocation – from SSA to non-SSA machine instructions</h3>Apart from some well-defined exceptions, the code generated from the instruction selector is in SSA form. In particular, it assumes it has an infinite set of "virtual" registers to act on. This, of course, isn’t true. Therefore, the next step of the code generator is to invoke a "register allocator", whose task is to replace virtual by physical registers, from the target’s register bank.<br><br>The exceptions mentioned above are also important and interesting, so let’s talk about them a bit more.<br><br>Some instructions in some architectures require fixed registers. A good example is our division instruction in x86, which requires its inputs to be in the EDX and EAX registers. The instruction selector knows about these restrictions, so as we can see in the code above, the inputs to <tt class="docutils literal">IDIV32r</tt> are physical, not virtual registers. This assignment is done by <tt class="docutils literal"><span class=pre>X86DAGToDAGISel::Select</span></tt>.<br><br>The register allocator takes care of all the non-fixed registers. There are a few more optimization (and pseudo-instruction expansion) steps that happen on machine instructions in SSA form, but I’m going to skip these. Similarly, I’m not going to discuss the steps performed after register allocation, since these don’t change the basic form operations appear in (<tt class="docutils literal">MachineInstr</tt>, at this point). If you’re interested, take a look at <tt class="docutils literal"><span class=pre>TargetPassConfig::addMachinePasses</span></tt>.<br><br>Here's the MIs dumped after register allocation:<br><br><pre style=line-height:125%><span style="font-family:courier new,Courier,monospace"><span style=font-size:x-small><br># After Virtual Register Rewriter:<br># Machine code for function foo: Post SSA<br>Function Live Ins: %EDI in %vreg0, %ESI in %vreg1, %EDX in %vreg2<br>Function Live Outs: %EAX<br><br>0B      BB#0: derived from LLVM BB %entry<br>            Live Ins: %EDI %ESI %EDX<br>16B             %ECX<def> = COPY %EDX<br>64B             %EAX<def> = LEA64_32r %EDI<kill>, 1, %ESI<kill>, 0, %noreg<br>96B             CDQ %EAX<imp-def>, %EDX<imp-def>, %EAX<imp-use><br>112B            IDIV32r %ECX<kill>, %EAX<imp-def>, %EDX<imp-def dead=dead>, %EFLAGS<imp-def dead=dead>, %EAX<imp-use>, %EDX<imp-use><br>160B            RET %EAX<imp-use><br><br># End machine code for function foo.<br></imp-use></imp-use></imp-use></imp-def></imp-def></imp-def></kill></imp-use></imp-def></imp-def></kill></kill></def></def></span></span></pre><br></div><div class=section id=emitting-code><h3>Emitting code</h3>So we now have our original C function translated to MI form – a <tt class="docutils literal">MachineFunction</tt> filled with instruction objects (<tt class="docutils literal">MachineInstr</tt>). This is the point at which the code generator has finished its job and we can emit the code. In current LLVM, there are two ways to do that. One is the (legacy) JIT which emits executable, ready-to-run code directly into memory. The other is MC, which is an ambitious object-file-and-assembly framework that’s been part of LLVM for a couple of years, replacing the previous assembly generator. MC is currently being used for assembly and object file emission for all (or at least the important) LLVM targets. MC also enables "MCJIT", which is a JIT-ting framework based on the MC layer. This is why I’m referring to LLVM’s JIT module as legacy.<br><br>I will first say a few words about the legacy JIT and then turn to MC, which is more universally interesting.<br><br>The sequence of passes to JIT-emit code is defined by <tt class="docutils literal"><span class=pre>LLVMTargetMachine::addPassesToEmitMachineCode</span></tt>. It calls <tt class="docutils literal">addPassesToGenerateCode</tt>, which defines all the passes required to do what most of this article has been talking about until now – turning IR into MI form. Next, it calls <tt class="docutils literal">addCodeEmitter</tt>, which is a target-specific pass for converting MIs into actual machine code. Since MIs are already very low-level, it’s fairly straightforward to translate them to runnable machine code. The x86 code for that lives in <tt class="docutils literal">lib/Target/X86/X86CodeEmitter.cpp</tt>. For our division instruction there’s no special handling here, because the <tt class="docutils literal">MachineInstr</tt> it’s packaged in already contains its opcode and operands. It is handled generically with other instructions in <tt class="docutils literal">emitInstruction</tt>.</div><h3>MCInst</h3>When LLVM is used as a static compiler (as part of <tt class="docutils literal">clang</tt>, for instance), MIs are passed down to the MC layer which handles the object-file emission (it can also emit textual assembly files). Much can be said about MC, but that would require an article of its own. A good reference is <a class="reference external" href=http://blog.llvm.org/2010/04/intro-to-llvm-mc-project.html>this post from the LLVM blog</a>. I will keep focusing on the path a single instruction takes.<br><br><tt class="docutils literal"><span class=pre>LLVMTargetMachine::addPassesToEmitFile</span></tt> is responsible for defining the sequence of actions required to emit an object file. The actual MI-to-<tt class="docutils literal">MCInst</tt> translation is done in the <tt class="docutils literal">EmitInstruction</tt> of the <tt class="docutils literal">AsmPrinter</tt> interface. For x86, this method is implemented by <tt class="docutils literal"><span class=pre>X86AsmPrinter::EmitInstruction</span></tt>, which delegates the work to the <tt class="docutils literal">X86MCInstLower</tt> class. Similarly to the JIT path, there is no special handling for our division instruction at this point, and it’s treated generically with other instructions.<br><br>By passing <tt class="docutils literal"><span class=pre>-show-mc-inst</span></tt> and <tt>-show-mc-encoding</tt> to <tt class="docutils literal">llc</tt>, we can see the MC-level instructions it creates with their encoding, alongside the actual assembly code:<br><br><pre style=line-height:125%><span style="font-family:courier new,Courier,monospace"><span style=font-size:x-small><br>foo:                                    # @foo<br># BB#0:                                 # %entry<br>      movl    %edx, %ecx              # encoding: [0x89,0xd1]<br>                                        # &lt;MCInst #1483 MOV32rr<br>                                        #  &lt;MCOperand Reg:46&gt;<br>                                        #  &lt;MCOperand Reg:48&gt;&gt;<br>      leal    (%rdi,%rsi), %eax       # encoding: [0x8d,0x04,0x37]<br>                                        # &lt;MCInst #1096 LEA64_32r<br>                                        #  &lt;MCOperand Reg:43&gt;<br>                                        #  &lt;MCOperand Reg:110&gt;<br>                                        #  &lt;MCOperand Imm:1&gt;<br>                                        #  &lt;MCOperand Reg:114&gt;<br>                                        #  &lt;MCOperand Imm:0&gt;<br>                                        #  &lt;MCOperand Reg:0&gt;&gt;<br>      cltd                            # encoding: [0x99]<br>                                        # &lt;MCInst #352 CDQ&gt;<br>      idivl   %ecx                    # encoding: [0xf7,0xf9]<br>                                        # &lt;MCInst #841 IDIV32r<br>                                        #  &lt;MCOperand Reg:46&gt;&gt;<br>      ret                             # encoding: [0xc3]<br>                                        # &lt;MCInst #2227 RET&gt;<br>.Ltmp0:<br>      .size   foo, .Ltmp0-foo<br></span></span></pre><br><br>The object file (or assembly code) emission is done by implementing the <tt class="docutils literal">MCStreamer</tt> interface. Object files are emitted by <tt class="docutils literal">MCObjectStreamer</tt>, which is further subclassed according to the actual object file format. For example, ELF emission is implemented in <tt class="docutils literal">MCELFStreamer</tt>. The rough path a <tt class="docutils literal">MCInst</tt> travels through the streamers is <tt class="docutils literal"><span class=pre>MCObjectStreamer::EmitInstruction</span></tt> followed by a format-specific <tt class="docutils literal">EmitInstToData</tt>. The final emission of the instruction in binary form is, of course, target-specific. It’s handled by the <tt class="docutils literal">MCCodeEmitter</tt> interface (for example <tt class="docutils literal">X86MCCodeEmitter</tt>). While in the rest of LLVM code is often tricky because it has to make a separation between target-independent and target-specific capabilities, MC is even more challenging because it adds another dimension – different object file formats. So some code is completely generic, some code is format-dependent, and some code is target-dependent.<br><h3>Assemblers and disassemblers</h3>A <tt class="docutils literal">MCInst</tt> is deliberately a very simple representation. It tries to shed as much semantic information as possible, keeping only the instruction opcode and list of operands (and a source location for assembler diagnostics). Like LLVM IR, it’s an internal representation will multiple possible encodings. The two most obvious are assembly (as shown above) and binary object files.<br><br><tt class="docutils literal"><span class=pre>llvm-mc</span></tt> is a tool that uses the MC framework to implement assemblers and disassemblers. Internally, <tt class="docutils literal">MCInst</tt> is the representation used to translate between the binary and textual forms. At this point the tool doesn’t care which compiler produced the assembly / object file.<br><br><h3>Conclusion</h3><br>Presenting a "big picture" view of a complex system as LLVM isn't easy. I hope that this article succeeds in giving some clues about the internal workings of LLVM in a way that is useful for further exploration.<br><pre style=line-height:125%>&nbsp;</pre><i>[This article is re-posted in a slightly expanded form <a href=http://eli.thegreenplace.net/2012/11/24/life-of-an-instruction-in-llvm/>from here</a>]</i><br><br><br></article><section class=post-nav><ul><li><a href=https://blog.llvm.org/2012/01/llvm-developer-meeting-2011.html><i class="fa fa-chevron-circle-left"></i> LLVM Developer Meeting 2011</a></li><li><a href=https://blog.llvm.org/2012/12/llvm-developer-meeting-2012.html>LLVM Developer Meeting 2012 <i class="fa fa-chevron-circle-right"></i></a></li></ul></section></main><footer><ul><li><h6>llvm.org |
Rendered by <a href=https://gohugo.io title=Hugo>Hugo</a> |
<a href=https://blog.llvm.org/index.xml>Subscribe</a></h6></li></ul></footer></div><script src=https://blog.llvm.org/js/scripts.js></script></body></html>